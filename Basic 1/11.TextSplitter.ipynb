{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Splitter\n",
    "\n",
    "1. Once you have loaded the documents, might want to transform them to better suit your application.\n",
    "2. Eg : split long document into smaller chunck that can fit into your model's context window.\n",
    "3. Split your document and send it to your model.\n",
    "4. Eg: html - splits text based on markdown-specific charaters. Code - splits text based on characters specific to the coding language. Token- splits text on token....\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.text_splitter import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Welcome to our sample text file!\\n\\nThis file is created to serve as a source for the Langchain document loader. \\n\\nIt contains a variety of sentences and paragraphs to test the functionality and efficiency of the loader.\\n\\nWe have included different types of text, such as:\\n\\n1. Descriptive paragraphs\\n2. Bullet point lists\\n3. Numbered lists\\n4. Dialogue examples\\n5. Quotes from famous authors\\n6. Random sentences with various punctuation and formatting\\n\\nFeel free to use this file to load into the Langchain document loader and see how it processes the content.\\n\\nThank you for choosing our sample text file for your testing needs!\\n\\nBest regards,\\nThe Langchain Team\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split by character\n",
    "with open('./data/sample.txt') as f:\n",
    "    sample_data = f.read()\n",
    "sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(separator=\"\\n\\n\",chunk_size = 200)\n",
    "mydata = text_splitter.create_documents([sample_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to our sample text file!\n",
      "\n",
      "This file is created to serve as a source for the Langchain document loader.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text_splitter = CharacterTextSplitter(separator=\"\\n\\n\",chunk_size = 100,chunk_overlap = 0)\n",
    "print(mydata[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split Code\n",
    "allow you to split your code in multiple languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cpp',\n",
       " 'go',\n",
       " 'java',\n",
       " 'kotlin',\n",
       " 'js',\n",
       " 'ts',\n",
       " 'php',\n",
       " 'proto',\n",
       " 'python',\n",
       " 'rst',\n",
       " 'ruby',\n",
       " 'rust',\n",
       " 'scala',\n",
       " 'swift',\n",
       " 'markdown',\n",
       " 'latex',\n",
       " 'html',\n",
       " 'sol',\n",
       " 'csharp',\n",
       " 'cobol',\n",
       " 'c',\n",
       " 'lua',\n",
       " 'perl']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import Language, RecursiveCharacterTextSplitter\n",
    "[e.value for e in Language] # shows a list of supported languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='def hello_world():'), Document(page_content='print(\"Hello world!\")'), Document(page_content='#Call the funtion'), Document(page_content='hello_world()')]\n"
     ]
    }
   ],
   "source": [
    "Python_code = \"\"\" def hello_world(): \n",
    "                    print(\"Hello world!\") \n",
    "                    #Call the funtion \n",
    "                    hello_world()\"\"\"\n",
    "python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PYTHON, chunk_size = 50, chunk_overlap = 0\n",
    ")\n",
    "python_docs = python_splitter.create_documents([Python_code])\n",
    "print(python_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
