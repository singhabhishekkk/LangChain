{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contextual Compression\n",
    "1. When retrieval with vector storage, there may be some cases where the accurate response to your query may be burried deep inside the irrelevant stuff in your vector database\n",
    "   \n",
    "\n",
    "2. i.e., you are not able to extract ot retieve the specific relevant data\n",
    "\n",
    "\n",
    "\n",
    "3. Also passing the full document through your application can lead to more expensive LLM call and poorer responses\n",
    "\n",
    "4. Idea : instead of immediately returning retrieved document as-is, you can compress them using the context of the given query -> so that relavant information is returned.\n",
    "\n",
    "5. Compression here = compressing the contents of individual document + filtering out document wholesale.\n",
    "\n",
    "6. Contextual Compression requires : a base retrieval + a document compressor\n",
    "\n",
    "7. Contextual Compression Retirever : 1. passes queries to base retiever. 2. takes the initial document and passes them through Document Compressor 3. Document compressor takes a list of document and shortens it by reducing the contents of document or dropping documents together\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yourkeyhere'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "SECRET_KEY = os.environ.get('OPEN_AI_KEY') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "# %pip install chromadb\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "\n",
    "chat = ChatOpenAI(openai_api_key = SECRET_KEY)\n",
    "\n",
    "# Load documents\n",
    "loader = TextLoader('./data/sample.txt')\n",
    "mydata = loader.load()\n",
    "\n",
    "# Split document\n",
    "text_splitter = CharacterTextSplitter(chunk_size = 100, chunk_overlap = 0)\n",
    "my_document = text_splitter.split_documents(mydata)\n",
    "\n",
    "# Embbed Model Object\n",
    "embedding_function = OpenAIEmbeddings(openai_api_key = SECRET_KEY)\n",
    "\n",
    "# Store - will store your documents vectors\n",
    "db = Chroma.from_documents(my_document, embedding_function, presist_directory = './chro_db')\n",
    "db.persist()\n",
    "\n",
    "# Read From ChromaDB\n",
    "db_connection = Chroma(embedding_function = embedding_function, presist_directory = './chro_db')\n",
    "\n",
    "\n",
    "query = \"How did India grew ? \"\n",
    "\n",
    "# Compression\n",
    "compressor = LLMChainExtractor.from_llm(chat)\n",
    "\n",
    "# Contextual Compression\n",
    "compressor_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=db_connection.as_retriever()\n",
    ")\n",
    "\n",
    "# Vector Store Retriever\n",
    "retriever = db_connection.as_retriever(search_kwargs={'k':1})\n",
    "similar_docs = retriever.get_relevant_documents(query)\n",
    "print(\"Without Compression : \",similar_docs)\n",
    "\n",
    "\n",
    "\n",
    "# With compressor\n",
    "\n",
    "similar_docs = compressor_retriever.get_relevant_documents(query)\n",
    "print(similar_docs.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
